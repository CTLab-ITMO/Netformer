# Netformer Library

Наша библиотека предназначена для облегчения исследований в области поиска нейронных архитектур (NAS).

## Features

### Генератор случайных моделей
Для создания набора моделей мы разработали настраиваемый генератор случайных моделей. Эти модели обучаются на случайных задачах регрессии.

### Токенизация моделей
Чтобы обучить трансформатор на этих моделях, мы токенизировали обученные модели.

### Смешанный loss на основе чувствительности нейронов

Во время обучения мы используем смешанную функцию потерь, основанную на чувствительности нейронов. Концепция чувствительности нейронов представлена в статье "[SeReNe: Sensitivity based Regularization of
Neurons for Structured Sparsity in Neural Networks](https://arxiv.org/pdf/2102.03773)".

Наша комбинированная функция потерь направлена на эффективное управление процессом обучения, учитывая множество аспектов генерируемых моделей. Она состоит из двух частей:

1. Предсказание типа и количества вершин (CrossEntropy Loss)
2. Прогнозирование веса краев (средняя квадратичная ошибка с учетом чувствительности нейронов)

**Прогнозирование типа и количества вершин (CrossEntropy Loss)**.

В этой части мы сосредоточимся на предсказании типа вершины, ее номера и номера ее родителя. Для этого мы используем CrossEntropyLoss, так как он хорошо подходит для задач многоклассовой классификации.

Для каждой вершины мы предсказываем ее тип (например, Linear, Tanh, ReLU), ее номер в графе и номер ее родителя в структуре графа. Используя CrossEntropyLoss, мы стремимся минимизировать расхождение между предсказанными и истинными значениями этих атрибутов.

**Прогнозирование веса ребра** (средняя квадратичная ошибка с чувствительностью нейронов)

В этой части мы сосредоточимся на предсказании весов ребер между вершинами. В качестве функции потерь для этой задачи регрессии мы используем среднюю квадратичную ошибку (MSE). Однако, чтобы повысить устойчивость процесса обучения и лучше справляться с промахами среди предсказанных моделей, мы используем концепцию чувствительности нейронов.

Чувствительность нейронов дает представление о важности каждого нейрона в архитектуре модели. Мы умножаем потерю MSE на чувствительность каждого нейрона, а затем суммируем их. Это позволяет придать больший вес ребрам, связанным с нейронами, которые считаются более чувствительными, тем самым подчеркивая их влияние на общую архитектуру.

### Метрики

Мы используем различные метрики для оценки сгенерированных моделей:

1. **Косинусное расстояние**: Мы рассчитываем косинусное расстояние между сгенерированной моделью и исходной моделью, исключая последний слой. Это помогает понять, насколько близка сгенерированная архитектура к исходной с точки зрения структуры и функциональности.
2. **Точность угаданных рёбер**: Эта метрика оценивает, насколько точно угаданы рёбра (связи между нейронами) сгенерированной модели совпадают с рёбрами исходной модели.

### Конкатенация мета-функций

#### Отобранные мета-функции
Мы тщательно выбираем следующие мета-функции из библиотеки [pymse](https://pymse.readthedocs.io/en/latest/), считая их очень важными для описания модели:

- **inst_to_attr**: Представляет собой отношение экземпляров к атрибутам.
- **nr_class**: Указывает на общее количество классов, присутствующих в модели.
- **nr_attr**: Обозначает общее количество атрибутов в модели.
- **attr_to_inst**: Отражает соотношение атрибутов и экземпляров.
- **skewness**: Измеряет перекос распределения данных в модели.
- **kurtosis**: Определяет эксцесс распределения данных модели.
- **cor**: Иллюстрирует корреляцию между различными атрибутами модели.
- **cov**: Представляет ковариацию между атрибутами модели.
- **attr_conc**: Указывает на концентрацию атрибутов в модели.
- **class_conc**: Указывает на концентрацию классов в модели.
- **sparsity**: Описывает уровень разреженности модели.
- **gravity**: Представляет меру гравитации модели.
- **class_ent**: Отражает энтропию классов в модели.
- **attr_ent**: Обозначает энтропию атрибутов в модели.
- **mut_inf**: Измеряет взаимную информацию модели.
- **eq_num_attr**: Указывает, имеет ли модель равное количество атрибутов.
- **ns_ratio**: Представляет собой соотношение чувствительности нейронов в модели.
- **f1, f2**: Функции 1 и 2, описывающие специфические характеристики модели.
- **tree_depth**: Представляет глубину древовидной структуры модели.
- **leaves_branch**: Указывает количество листьев на ветвь в модели.
- **nodes_per_attr**: Обозначает количество узлов на атрибут в модели.
- **leaves_per_class**: Обозначает количество листьев на класс в модели.

Дополняя каждый токен модели этими метафичами, мы улучшаем понимание структуры, характеристик и свойств модели. Такое дополнение способствует улучшению способности модели к восприятию и обработке данных, что приводит к более точным и качественным предсказаниям.

Вы можете получить его, просто вызвав `meta_features = get_meta_features(parameters, target)` с соответствующими массивами параметров и целей для каждого набора данных.

## Процесс обучения

1. **Энкодер**: Кодер трансформатора обрабатывает токенизированные модели для создания эмбеддинги.
2. **Эмбеддинг**: Эти эмбеддинги объединяются с метафичами.
3. **Вариационная часть**: Конкатенированные эмбеддинги проходят через вариационную часть трансформатора.
4. **Декодер**: Декодер переводит вариативные эмбеддинги обратно в лексемы.
5. **Обратное преобразование**: Токены преобразуются обратно в модели и оцениваются на основе метрик.



## Inference

Берём эмбеддинг нормального распределения. Затем прогоняем через трансформер и получаем предсказание.

## Установка

Укажите шаги для установки вашей библиотеки, включая все зависимости.

```bash
pip install -r requirements.txt
```

## Запуск примера

```bash
bash lib/generator/install_datasets.sh
cp example/train_loop_example.py .
python train_loop_example.py
```